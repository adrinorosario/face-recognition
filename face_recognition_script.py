# -*- coding: utf-8 -*-
"""face_recognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1S0Syzu2NNDnAlueHPsNNdgyJ4VPg1lB5
"""

import numpy as np
import cv2 as cv
import os
import re

"""
1: Gather all images and detect the faces
2: Mark the faces of all the images
3: Crop out the faces from each image and place them in a seperate folder (must be named the same as parent
folder which contained the actual non-edited image)
4: Pass in the cropped images and train
5: Test the model on unedited and uncropped images
"""

"""
Create an algorithm/function that sorts pictures.
Take a picture and first identiy the number of faces. If there is one, then its an individual picture, two- then duet or trio if three or group if more.
Then, try to identify group pictures, if two or more people appear in more than two pictures and sort them accordingly into different groups.
Then sort them based on colour(try it, not sure)
Try sorting them based on background. Crop out a particular piece of the picture away from the faces and sort based on it.
[DO THE ABOVE BASED ON PREVIOUS NOTES; REFERENCE]
"""

"""
Try sorting out landscapes: River, Lakes, Oceans, Marshes, Ponds, Valleys, Mountains(snonwy and rocky).
"""

from google.colab import files
uploaded = files.upload()

haar_cascade = cv.CascadeClassifier('/content/harr_face_default.xml')

people = ['Emma Watson', 'Emily Blunt', 'JK Rowling', 'Rubeus Hagrid', 'Alan Rickman']

face_recognizer = cv.face.LBPHFaceRecognizer_create()

# Commented out IPython magic to ensure Python compatibility.
!unzip Archive.zip
# %ls

# Commented out IPython magic to ensure Python compatibility.
# %ls

file_names_and_persons = dict()
get_name = lambda path: re.sub(r'^/content/', '', path)

def get_names(folder_name, dictionary: dict):
  for files in os.listdir(folder_name):
    dictionary[files] = get_name(folder_name)

get_names('/content/Alan Rickman', file_names_and_persons)
get_names('/content/Emily Blunt', file_names_and_persons)
get_names('/content/Emma Watson', file_names_and_persons)
get_names('/content/JK Rowling', file_names_and_persons)
get_names('/content/Rubeus Hagrid', file_names_and_persons)

for file_name, name in file_names_and_persons.items():
  print(file_name, ": ", name)

print(len(file_names_and_persons))

file_names_and_persons2 = dict()

get_names('/content/Alan Rickman', file_names_and_persons2)
get_names('/content/Emily Blunt', file_names_and_persons2)
#get_names('/content/Emma Watson', file_names_and_persons2)
#get_names('/content/JK Rowling', file_names_and_persons2)
#get_names('/content/Rubeus Hagrid', file_names_and_persons2)

file_name_and_persons = dict()

get_names('/content/Alan Rickman', file_name_and_persons)
get_names('/content/Emily Blunt', file_name_and_persons)
get_names('/content/Emma Watson', file_name_and_persons)
get_names('/content/JK Rowling', file_name_and_persons)
get_names('/content/Rubeus Hagrid', file_name_and_persons)

print(len(file_name_and_persons))

for file_name, name in file_name_and_persons.items():
  print(file_name, ": ", name)

# Commented out IPython magic to ensure Python compatibility.
!unzip persons.zip
# %ls

DIR = '/content/persons/'

features = []
labels = []

check_extension = lambda path: 1 if re.search(r'\.(jpeg|jpg|png)$', path, re.IGNORECASE) else 0

def create_training_set():
  for person in people:
    path = DIR + person
    label = people.index(person)

    for image in os.listdir(path):
      image_path = os.path.join(path,image)


      if check_extension(image_path) == 1:
        gray = cv.imread(image_path)
        #print(image_array.shape)
        #print(image_path)
        grayed = cv.cvtColor(gray,cv.COLOR_BGR2GRAY)

        faces_rect = haar_cascade.detectMultiScale(grayed, scaleFactor=1.1, minNeighbors=4)

        for (x,y,w,h) in faces_rect:
          faces_region_of_interest = grayed[y:y+h, x:x+w]
          features.append(faces_region_of_interest)
          labels.append(label)
      else:
        continue

create_training_set()
print(f"Length of features: {len(features)}")
print(f"Length of labels: {len(labels)}")

face_recognizer = cv.face.LBPHFaceRecognizer_create()

np_features = np.array(features, dtype='object')
np_labels = np.array(labels)

face_recognizer.train(np_features, np_labels)

np.save('features.npy', np_features)
np.save('labels.npy', np_labels)

face_recognizer.save('faces_trained.yml')

"""The training of the model is now complete. Now we can use the model to recognise faces and, essentially, perform face recognition."""

# Commented out IPython magic to ensure Python compatibility.
upload_val = files.upload()

!unzip emily_val.zip
# %ls

facesRecognizer = cv.face.LBPHFaceRecognizer_create()
facesRecognizer.read('/content/faces_trained.yml')

def recognize_a_single_image(image_path):
  image = cv.imread(image_path)
  gray = cv.cvtColor(image,cv.COLOR_BGR2GRAY)

  faces_rect = haar_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=4)

  for(x,y,w,h) in faces_rect:
    face_region_of_interest = gray[y:y+h, x:x+w]

    label, accuracy = facesRecognizer.predict(face_region_of_interest)

  print(f"This is {people[label]} with an accuracy of {accuracy}%")

#recognize_a_single_image('/content/Emily Blunt/images (17).jpeg')

def recognize_a_folder_of_images(folder_path):
  for images in os.listdir(folder_path):
    image_path = os.path.join(folder_path + "/", images)

    if check_extension(image_path) == 1:
      image_read = cv.imread(image_path)
      grayed = cv.cvtColor(image_read, cv.COLOR_BGR2GRAY)

      faces_rect = haar_cascade.detectMultiScale(grayed, 1.1, 4)

      for(x,y,w,h) in faces_rect:
        face_region_of_interest = grayed[y:y+h, x:x+w]

        label, accuracy = facesRecognizer.predict(face_region_of_interest)

      print(f"This is {people[label]} with an accuracy of {accuracy}%")


recognize_a_folder_of_images('/content/emily_val')

# Commented out IPython magic to ensure Python compatibility.
haar_eye_xml_upload = files.upload()
# %ls

haar_eye_cascade = cv.CascadeClassifier('/content/haar_eye.xml')

eye_features = []
eye_labels = []
DIR = '/content/persons/'

check_extension = lambda path: 1 if re.search(r'\.(jpeg|jpg|png)$', path, re.IGNORECASE) else 0


def create_eye_training_set():
  for person in people:
    path = DIR + person
    label = people.index(person)

    for images in os.listdir(path):
      image_path = os.path.join(path, images)


      if check_extension(image_path) == 1:
        image = cv.imread(image_path)
        grayed = cv.cvtColor(image, cv.COLOR_BGR2GRAY)

        eye_rect = haar_eye_cascade.detectMultiScale(image, 1.1, 4)

        for(x,y,w,h) in eye_rect:
          region_of_interest = image[y:y+h, x:x+w]
          eye_features.append(region_of_interest)
          eye_labels.append(label)
      else:
        continue

create_eye_training_set()
print(f'Length of features: {len(eye_features)}')
print(f'Length of labels: {len(eye_labels)}')